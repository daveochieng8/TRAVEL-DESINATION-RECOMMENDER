{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (18040, 4)\n",
      "Training set size: 14432\n",
      "Test set size: 3608\n",
      "Training pipeline...\n",
      "Original input shape: 14432\n",
      "Transformed output shape: 14432\n",
      "Original input shape: 14432\n",
      "Transformed output shape: 14432\n",
      "Original input shape: 3608\n",
      "Transformed output shape: 3608\n",
      "Original input shape: 14432\n",
      "Transformed output shape: 14432\n",
      "Original input shape: 3608\n",
      "Transformed output shape: 3608\n",
      "Original input shape: 3608\n",
      "Transformed output shape: 3608\n",
      "\n",
      "Model Performance:\n",
      "Training Accuracy: 0.7455\n",
      "Test Accuracy: 0.5496\n",
      "Training F1: 0.7634\n",
      "Test F1: 0.5709\n",
      "\n",
      "Detailed Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.60      0.29      0.39        72\n",
      "           Australia       0.44      0.56      0.49       240\n",
      "              Brazil       0.84      0.47      0.61       120\n",
      "              Canada       0.20      0.65      0.30       240\n",
      "               Chile       0.58      0.30      0.39        64\n",
      "               China       0.69      0.54      0.61       240\n",
      "               Egypt       0.72      0.74      0.73       104\n",
      "                Fiji       0.67      0.25      0.36        16\n",
      "              France       0.67      0.56      0.61       240\n",
      "             Germany       0.79      0.52      0.63       240\n",
      "               India       0.58      0.58      0.58       240\n",
      "              Israel       0.41      0.41      0.41        32\n",
      "               Italy       0.63      0.64      0.63       240\n",
      "               Japan       0.71      0.58      0.64       240\n",
      "              Jordan       0.59      0.53      0.56        32\n",
      "               Kenya       0.41      0.34      0.37        32\n",
      "              Mexico       0.66      0.63      0.65       216\n",
      "             Morocco       0.81      0.36      0.50        72\n",
      "         New Zealand       0.60      0.35      0.44        80\n",
      "                Peru       0.75      0.46      0.57        72\n",
      "        South Africa       0.64      0.40      0.49       128\n",
      "            Thailand       0.91      0.68      0.78       176\n",
      "              Turkey       0.85      0.61      0.71       208\n",
      "United Arab Emirates       0.63      0.50      0.56        24\n",
      "       United States       0.48      0.50      0.49       240\n",
      "\n",
      "            accuracy                           0.55      3608\n",
      "           macro avg       0.63      0.50      0.54      3608\n",
      "        weighted avg       0.64      0.55      0.57      3608\n",
      "\n",
      "\n",
      "Pipeline saved as 'destination_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "# destination_classifier.py\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from custom_preprocessors import PreprocessText  # Import from separate file\n",
    "\n",
    "def build_destination_classifier(data_path):\n",
    "    \"\"\"\n",
    "    Build and train a destination classifier with proper preprocessing\n",
    "    \n",
    "    Parameters:\n",
    "    data_path (str): Path to the CSV file containing destination data\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (trained_pipeline, evaluation_metrics)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        data = pd.read_csv(data_path)\n",
    "        print(f\"Loaded data shape: {data.shape}\")\n",
    "        \n",
    "        # Validate data\n",
    "        for col in ['Description', 'Country']:\n",
    "            if col not in data.columns:\n",
    "                raise ValueError(f\"Missing required column: {col}\")\n",
    "            if data[col].isnull().any():\n",
    "                raise ValueError(f\"Found null values in column: {col}\")\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = data['Description']\n",
    "        y = data['Country']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, \n",
    "            stratify=y if len(y.unique()) > 1 else None\n",
    "        )\n",
    "        print(f\"Training set size: {len(X_train)}\")\n",
    "        print(f\"Test set size: {len(X_test)}\")\n",
    "        \n",
    "        # Define stopwords\n",
    "        new_stopwords = ['and', 'the', 'or', 'but'] + list(string.punctuation)\n",
    "        \n",
    "        # Build pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('preprocess', PreprocessText()),\n",
    "            ('vectorize', CountVectorizer(\n",
    "                analyzer='word',\n",
    "                stop_words=new_stopwords,\n",
    "                decode_error='ignore',\n",
    "                min_df=2\n",
    "            )),\n",
    "            ('classifier', GradientBoostingClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Train pipeline\n",
    "        print(\"Training pipeline...\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(pipe, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        return pipe, metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in pipeline: {str(e)}\")\n",
    "\n",
    "def evaluate_model(pipe, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model and return performance metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'train_accuracy': accuracy_score(y_train, pipe.predict(X_train)),\n",
    "        'test_accuracy': accuracy_score(y_test, pipe.predict(X_test)),\n",
    "        'train_f1': f1_score(y_train, pipe.predict(X_train), average='weighted'),\n",
    "        'test_f1': f1_score(y_test, pipe.predict(X_test), average='weighted'),\n",
    "        'classification_report': classification_report(y_test, pipe.predict(X_test))\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def save_model(pipe, filename='destination_pipeline.pkl'):\n",
    "    \"\"\"\n",
    "    Save the trained pipeline to a file\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(pipe, f)\n",
    "    print(f\"\\nPipeline saved as '{filename}'\")\n",
    "\n",
    "def load_model(filename='destination_pipeline.pkl'):\n",
    "    \"\"\"\n",
    "    Load a trained pipeline from a file\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        pipe = pickle.load(f)\n",
    "    return pipe\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Build and evaluate model\n",
    "        pipe, metrics = build_destination_classifier(\"best_travel_destinations_for_2025.csv\")\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(f\"Training Accuracy: {metrics['train_accuracy']:.4f}\")\n",
    "        print(f\"Test Accuracy: {metrics['test_accuracy']:.4f}\")\n",
    "        print(f\"Training F1: {metrics['train_f1']:.4f}\")\n",
    "        print(f\"Test F1: {metrics['test_f1']:.4f}\")\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(metrics['classification_report'])\n",
    "        \n",
    "        # Save model\n",
    "        save_model(pipe)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
